{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d10eb53-438f-4543-9d5a-5160e70c3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6327ca25-fcbd-4fa6-a90e-ff4ee21a7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for different scene elements\n",
    "class Material:\n",
    "    def __init__(self, Cs, Ka, Kd, Ks, Kt, n):\n",
    "        self.Cs = Cs\n",
    "        self.Ka = Ka\n",
    "        self.Kd = Kd\n",
    "        self.Ks = Ks\n",
    "        self.Kt = Kt\n",
    "        self.n = n\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self, transform_type, value):\n",
    "        self.transform_type = transform_type\n",
    "        self.value = value\n",
    "\n",
    "class Shape:\n",
    "    def __init__(self, id, geometry, material, transforms, notes=\"\"):\n",
    "        self.id = id\n",
    "        self.geometry = geometry\n",
    "        self.material = material\n",
    "        self.transforms = transforms\n",
    "        self.notes = notes\n",
    "\n",
    "class Light:\n",
    "    def __init__(self, id, type, color, intensity, from_pos=None, to_pos=None):\n",
    "        self.id = id\n",
    "        self.type = type\n",
    "        self.color = color\n",
    "        self.intensity = intensity\n",
    "        self.from_pos = from_pos\n",
    "        self.to_pos = to_pos\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, from_pos, to_pos, bounds, resolution):\n",
    "        self.from_pos = from_pos\n",
    "        self.to_pos = to_pos\n",
    "        self.bounds = bounds\n",
    "        self.resolution = resolution\n",
    "\n",
    "# Parse the scene JSON file\n",
    "def parse_scene(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        scene_data = json.load(file)\n",
    "\n",
    "    shapes = []\n",
    "    lights = []\n",
    "    camera = None\n",
    "\n",
    "    # Parse shapes\n",
    "    for shape_data in scene_data['scene']['shapes']:\n",
    "        transforms = []\n",
    "        for transform_data in shape_data['transforms']:\n",
    "            transform_type, value = next(iter(transform_data.items()))\n",
    "            transforms.append(Transform(transform_type, value))\n",
    "        shapes.append(Shape(shape_data.get('id'), shape_data['geometry'], \n",
    "                            Material(shape_data['material']['Cs'], shape_data['material']['Ka'],\n",
    "                                     shape_data['material']['Kd'], shape_data['material']['Ks'],\n",
    "                                     shape_data['material']['Kt'], shape_data['material']['n']), \n",
    "                                     transforms, shape_data.get('notes')))\n",
    "\n",
    "    # Parse lights\n",
    "    for light_data in scene_data['scene']['lights']:\n",
    "        if light_data['type'] == 'ambient':\n",
    "            lights.append(Light(light_data['id'], 'ambient', light_data['color'], light_data['intensity']))\n",
    "        elif light_data['type'] == 'directional':\n",
    "            lights.append(Light(light_data['id'], 'directional', light_data['color'], light_data['intensity'],\n",
    "                                 light_data['from'], light_data['to']))\n",
    "\n",
    "    # Parse camera\n",
    "    camera_data = scene_data['scene']['camera']\n",
    "    camera = Camera(camera_data['from'], camera_data['to'], camera_data['bounds'], camera_data['resolution'])\n",
    "\n",
    "    return shapes, lights, camera\n",
    "\n",
    "# Test the parser\n",
    "shapes, lights, camera = parse_scene('scene.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0627481-556c-4411-a41c-f98b4eee68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_matrix(scale_factors):\n",
    "    if len(scale_factors) != 3:\n",
    "        raise ValueError(\"Scale factors must be provided for x, y, and z axes.\")\n",
    "    scale_matrix = np.diag(scale_factors + [1])  # Add 1 for the homogeneous coordinate\n",
    "    return scale_matrix\n",
    "\n",
    "def rotation_matrix_y(angle_deg):\n",
    "    angle_rad = np.radians(angle_deg)\n",
    "    cos_theta = np.cos(angle_rad)\n",
    "    sin_theta = np.sin(angle_rad)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_theta, 0, sin_theta, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [-sin_theta, 0, cos_theta, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    return rotation_matrix\n",
    "\n",
    "def translation_matrix(translation):\n",
    "    if len(translation) != 3:\n",
    "        raise ValueError(\"Translation must be provided for x, y, and z axes.\")\n",
    "    tx, ty, tz = translation\n",
    "    translation_matrix = np.array([\n",
    "        [1, 0, 0, tx],\n",
    "        [0, 1, 0, ty],\n",
    "        [0, 0, 1, tz],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    return translation_matrix\n",
    "\n",
    "def combine_transformations(scale_factors, angle_deg, translation):\n",
    "    scale_mat = scale_matrix(scale_factors)\n",
    "    rotation_mat_y = rotation_matrix_y(angle_deg)\n",
    "    translation_mat = translation_matrix(translation)\n",
    "    combined_mat = translation_mat @ rotation_mat_y @ scale_mat  # Order of application: scale, rotate, translate\n",
    "    return combined_mat\n",
    "\n",
    "def normal_combine_transformations(scale_factors, angle_deg):\n",
    "    scale_mat = scale_matrix(scale_factors)\n",
    "    rotation_mat_y = rotation_matrix_y(angle_deg)\n",
    "    # translation_mat = translation_matrix(translation)\n",
    "    combined_mat = rotation_mat_y @ scale_mat  # Order of application: scale, rotate, translate\n",
    "    return combined_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df567344-437e-43ee-93e2-5479f96b2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_camera_axes(cam_from, cam_to):\n",
    "    cam_up = [0, 1, 0]\n",
    "    n = np.array(cam_from, dtype=np.float64) - np.array(cam_to, dtype=np.float64)\n",
    "    n /= np.linalg.norm(n)\n",
    "    u = np.cross(np.array(cam_up, dtype=np.float64), n)\n",
    "    u /= np.linalg.norm(u)\n",
    "    v = np.cross(n, u)\n",
    "    r = cam_from\n",
    "    return u, v, n, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127de0ff-83e5-4a2d-8595-3bcce79f402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    return vector / np.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95d1dcd-093c-49a3-a0be-8a572d241b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_aliasing_table = np.array(\n",
    "        [\n",
    "            [-0.52, 0.38, 0.128],\n",
    "            [0.41, 0.56, 0.119],\n",
    "            [0.27, 0.08, 0.294],\n",
    "            [-0.17, -0.29, 0.249],\n",
    "            [0.58, -0.55, 0.104],\n",
    "            [-0.31, -0.71, 0.106],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3350f75-e3b3-4045-9c68-97abffe863ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_image_and_z_buffer(canvas_size):\n",
    "    image = Image.new('RGB', (canvas_size, canvas_size), (0, 0, 0))\n",
    "    z_buffer = np.full((canvas_size, canvas_size), np.inf, dtype=float)\n",
    "    return image, z_buffer\n",
    "\n",
    "def perspective_projection_matrix(near, far, left, right, top, bottom):\n",
    "    matrix = np.zeros((4, 4))\n",
    "    matrix[0, 0] = 2 * near / (right - left)\n",
    "    matrix[1, 1] = 2 * near / (top - bottom)\n",
    "    matrix[0, 2] = (right + left) / (right - left)\n",
    "    matrix[1, 2] = (top + bottom) / (top - bottom)\n",
    "    matrix[2, 2] = -(far + near) / (far - near)\n",
    "    matrix[2, 3] = -2 * far * near / (far - near)\n",
    "    matrix[3, 2] = -1\n",
    "    return matrix\n",
    "\n",
    "def camera_matrix(u, v, n, r):\n",
    "    matrix = np.eye(4)\n",
    "    matrix[0, :3] = u\n",
    "    matrix[1, :3] = v\n",
    "    matrix[2, :3] = n\n",
    "    matrix[3, :3] = 0, 0, 0\n",
    "    matrix[0, 3] = -np.dot(r, u)\n",
    "    matrix[1, 3] = -np.dot(r, v)\n",
    "    matrix[2, 3] = -np.dot(r, n)\n",
    "    matrix[3, 3] = 1\n",
    "    return matrix\n",
    "\n",
    "# Constants\n",
    "canvas_size = 512\n",
    "\n",
    "# Load teapot data from JSON\n",
    "with open('teapot.json', 'r') as f:\n",
    "    teapot_data = json.load(f)\n",
    "\n",
    "# Initialize image and z-buffer\n",
    "image, z_buffer = initialize_image_and_z_buffer(canvas_size)\n",
    "\n",
    "draw = ImageDraw.Draw(image)\n",
    "image_width, image_height = draw.im.size\n",
    "\n",
    "# Define the camera space axes\n",
    "u, v, n, r = calculate_camera_axes(camera.from_pos, camera.to_pos)\n",
    "near, far, right, left, top, bottom = camera.bounds\n",
    "\n",
    "# Create the camera matrix\n",
    "camera_mat = camera_matrix(u, v, n, r)\n",
    "# print(camera_mat)\n",
    "\n",
    "# Create perspective projection matrix\n",
    "perspective_mat = perspective_projection_matrix(near, far, left, right, top, bottom)\n",
    "# print(perspective_mat)\n",
    "\n",
    "camera_space_vertices = []\n",
    "normal_vertices = []\n",
    "raster_vertices = []\n",
    "texture_vertices = []\n",
    "\n",
    "for anti_aliasing_values in anti_aliasing_table:\n",
    "\n",
    "    anti_aliasing_dx = anti_aliasing_values[0] / (image_width - 1)\n",
    "    anti_aliasing_dy = anti_aliasing_values[1] / (image_height - 1)\n",
    "\n",
    "    camera_space_vertices_antialiasing_temp = []\n",
    "    raster_vertices_antialiasing_temp = []\n",
    "    normal_vertices_antialiasing_temp = []\n",
    "    texture_vertices_antialiasing_temp =[]\n",
    "    \n",
    "    for shape in shapes:\n",
    "        camera_space_vertices_temp = []\n",
    "        raster_vertices_temp = []\n",
    "        normal_vertices_temp = []\n",
    "        texture_vertices_temp = []\n",
    "        \n",
    "        combine_transformations_matrix = combine_transformations(shape.transforms[1].value, shape.transforms[0].value, shape.transforms[2].value)\n",
    "        inverse_transpose_matrix = np.linalg.inv(normal_combine_transformations(shape.transforms[1].value, shape.transforms[0].value)).T\n",
    "        \n",
    "        # print(combine_transformations_matrix)\n",
    "        # print(inverse_transpose_matrix)\n",
    "        \n",
    "        for triangle in teapot_data['data']:\n",
    "            camera_space_vertex = []\n",
    "            raster_vertex = []\n",
    "            normal_vertex = []\n",
    "            texture_vertex = []\n",
    "            for vertex in [triangle['v0'], triangle['v1'], triangle['v2']]:\n",
    "                v = np.array(vertex['v'][:3] + [1.0])  # Add 1.0 for 4D\n",
    "                v = combine_transformations_matrix @ v\n",
    "                \n",
    "                v_camera = camera_mat @ v\n",
    "                v_camera = v_camera[:3] / v_camera[3]\n",
    "                \n",
    "                camera_space_vertex.append([v_camera[0], v_camera[1], v_camera[2]])\n",
    "                \n",
    "                v_camera = np.append(v_camera, 1)\n",
    "                v_ndc = perspective_mat @ v_camera\n",
    "                v_ndc = v_ndc[:3] / v_ndc[3]\n",
    "                v_ndc = np.append(v_ndc, 1)\n",
    "                \n",
    "                x = ((v_ndc[0] + 1) * ((image_width-1) / 2)) + anti_aliasing_dx\n",
    "                y = ((1 - v_ndc[1]) * ((image_height-1) / 2)) + anti_aliasing_dy\n",
    "                z = v_ndc[2]\n",
    "                \n",
    "                raster_vertex.append((x, y, z))\n",
    "               \n",
    "                n = np.array(vertex['n'][:3] + [1.0])  # Add 1.0 for 4D\n",
    "                n = inverse_transpose_matrix @ n\n",
    "                n = n[:3] #/ n[3]\n",
    "                \n",
    "                normal_vertex.append(normalize(n))\n",
    "                # break\n",
    "    \n",
    "                t = np.array(vertex['t'])\n",
    "                texture_vertex.append(t)\n",
    "                \n",
    "            raster_vertices_temp.append(raster_vertex)\n",
    "            # print(raster_vertices_temp)\n",
    "            camera_space_vertices_temp.append(camera_space_vertex)\n",
    "            normal_vertices_temp.append(normal_vertex)\n",
    "            texture_vertices_temp.append(texture_vertex)\n",
    "            # print(texture_vertices_temp)\n",
    "            # break\n",
    "        # break\n",
    "    \n",
    "        raster_vertices_antialiasing_temp.append(raster_vertices_temp)\n",
    "        camera_space_vertices_antialiasing_temp.append(camera_space_vertices_temp)\n",
    "        normal_vertices_antialiasing_temp.append(normal_vertices_temp)\n",
    "        texture_vertices_antialiasing_temp.append(texture_vertices_temp)\n",
    "        \n",
    "    raster_vertices.append(raster_vertices_antialiasing_temp)\n",
    "    camera_space_vertices.append(camera_space_vertices_antialiasing_temp)\n",
    "    normal_vertices.append(normal_vertices_antialiasing_temp)\n",
    "    texture_vertices.append(texture_vertices_antialiasing_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6013597-0f6e-4cfd-a91c-1417dd92c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambient_intensity = lights[0].intensity\n",
    "light_intensity = lights[1].intensity\n",
    "light_direction = normalize([lights[1].from_pos[0] - lights[1].to_pos[0], lights[1].from_pos[1] - lights[1].to_pos[1], lights[1].from_pos[2] - lights[1].to_pos[2]])\n",
    "viewer_position = np.array(camera.from_pos)\n",
    "material_constants = {\"Cs\": np.array(shapes[0].material.Cs), \"Ka\": shapes[0].material.Ka, \"Kd\": shapes[0].material.Kd, \"Ks\": shapes[0].material.Ks, \"Kt\": shapes[0].material.Kt, \"n\": shapes[0].material.n}\n",
    "ambient_color = np.array(lights[0].color)\n",
    "light_color = np.array(lights[1].color)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a620b2-7895-4750-9525-a898c582954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(a, b):\n",
    "    return np.dot(a, b)\n",
    "\n",
    "def compute_diffuse(normal, light_direction, kd):\n",
    "    return max(0, dot_product(normal, light_direction)) * light_color * light_intensity * kd\n",
    "\n",
    "def compute_specular(normal, light_direction, vertex_position, ks, n):\n",
    "    view_direction = normalize(viewer_position - vertex_position)\n",
    "    H = normalize (light_direction + view_direction)\n",
    "    specular_term = max(0, dot_product(H, normal)) ** n\n",
    "    return specular_term * light_color * light_intensity * ks\n",
    "\n",
    "def compute_ambient(ka):\n",
    "    return ambient_intensity * ka * ambient_color\n",
    "\n",
    "def compute_illumination(normal, vertex_position):\n",
    "    Cs = material_constants[\"Cs\"]\n",
    "    Ka = material_constants[\"Ka\"]\n",
    "    Kd = material_constants[\"Kd\"]\n",
    "    Ks = material_constants[\"Ks\"]\n",
    "    n = material_constants[\"n\"]\n",
    "    ambient = compute_ambient(Ka)\n",
    "    diffuse = compute_diffuse(normal, light_direction, Kd)\n",
    "    specular = compute_specular(normal, light_direction, vertex_position, Ks, n)\n",
    "    return (Cs * (ambient + diffuse) + specular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10f4fa7-8d3b-4e3a-b5cc-ff6027817f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_map_file_name = \"flower.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e5c3ba-b71b-4525-ae67-8fa43cfd61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_im = Image.open(texture_map_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b55a982-19cb-4863-9c4d-e7d006170f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textureLookup(u, v, texmap):\n",
    "    # Compute fractional coordinates\n",
    "    xLocation = u * (texmap.size[0] - 1)\n",
    "    yLocation = v * (texmap.size[1] - 1)\n",
    "\n",
    "    # Compute the four adjacent pixels\n",
    "    p00 = (int(xLocation), int(yLocation))\n",
    "    p11 = (int(xLocation) + 1, int(yLocation) + 1)\n",
    "    p10 = (int(xLocation) + 1, int(yLocation))\n",
    "    p01 = (int(xLocation), int(yLocation) + 1)\n",
    "\n",
    "    # Get the RGB values of the four adjacent pixels\n",
    "    p00RGB = texmap.getpixel(p00)\n",
    "    p11RGB = texmap.getpixel(p11)\n",
    "    p10RGB = texmap.getpixel(p10)\n",
    "    p01RGB = texmap.getpixel(p01)\n",
    "\n",
    "    # Compute the fractional parts\n",
    "    f = xLocation - int(xLocation)\n",
    "    g = yLocation - int(yLocation)\n",
    "\n",
    "    # Perform bilinear interpolation\n",
    "    p0010RGB = tuple((1 - f) * p00RGB[i] + f * p10RGB[i] for i in range(3))\n",
    "    p0111RGB = tuple((1 - f) * p01RGB[i] + f * p11RGB[i] for i in range(3))\n",
    "    pOutputRGB = tuple((1 - g) * np.array(p0010RGB) + g * np.array(p0111RGB))\n",
    "\n",
    "    return np.array(pOutputRGB)\n",
    "\n",
    "def compute_triangle_color(u, v):\n",
    "    return textureLookup(u, v, texture_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4b1aca9-dc59-4e05-820e-d9d132582b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_eq(p1, p2, x, y):\n",
    "    return (p1[1] - p2[1]) * x + (p2[0] - p1[0]) * y + p1[0] * p2[1] - p2[0] * p1[1]\n",
    "\n",
    "def clip_and_clamp_coordinates(v0, v1, v2, canvas_width, canvas_height):\n",
    "    xmin, xmax = max(np.floor(min(v0[0], v1[0], v2[0])), 0), min(np.ceil(max(v0[0], v1[0], v2[0])), canvas_width - 1)\n",
    "    ymin, ymax = max(np.floor(min(v0[1], v1[1], v2[1])), 0), min(np.ceil(max(v0[1], v1[1], v2[1])), canvas_height - 1)\n",
    "    return int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "\n",
    "def rasterize_triangle(draw, z_buffer, raster_vertex, shade_vertex, texture_vertex):\n",
    "    # print(shade_vertex)\n",
    "    # print(texture_vertex)\n",
    "    v0, v1, v2 = raster_vertex[0], raster_vertex[1], raster_vertex[2]\n",
    "    t0, t1, t2 = texture_vertex[0], texture_vertex[1], texture_vertex[2]\n",
    "\n",
    "    canvas_width, canvas_height = draw.im.size\n",
    "\n",
    "    # Clip and clamp the triangle's bounding box coordinates\n",
    "    xmin, xmax, ymin, ymax = clip_and_clamp_coordinates(v0, v1, v2, canvas_width, canvas_height)\n",
    "\n",
    "    f12_v0 = line_eq(v1, v2, v0[0], v0[1])\n",
    "    f20_v1 = line_eq(v2, v0, v1[0], v1[1])\n",
    "    f01_v2 = line_eq(v0, v1, v2[0], v2[1])\n",
    "\n",
    "    for y in range(ymin, ymax):\n",
    "        for x in range(xmin, xmax):\n",
    "            alpha = line_eq(v1, v2, x, y) / f12_v0\n",
    "            beta = line_eq(v2, v0, x, y) / f20_v1\n",
    "            gamma = line_eq(v0, v1, x, y) / f01_v2\n",
    "\n",
    "            if 0 <= alpha <= 1 and 0 <= beta <= 1 and 0 <= gamma <= 1:\n",
    "                z = alpha * v0[2] + beta * v1[2] + gamma * v2[2]\n",
    "                # print(z_buffer[y, x])\n",
    "                if z < z_buffer[y, x]:\n",
    "                    # Load texture\n",
    "                    interpolated_t_over_z = np.array(alpha * t0 / v0[2] + beta * t1 / v1[2] + gamma * t2 / v2[2])\n",
    "                    z_at_pixel = 1 / np.array(alpha * (1 / v0[2]) + beta * (1 / v1[2]) + gamma * (1 / v2[2]))\n",
    "                    interpolated_t_over_z *= z_at_pixel\n",
    "                    texture_color = compute_triangle_color(interpolated_t_over_z[0], interpolated_t_over_z[1])\n",
    "                    \n",
    "                    # Interpolate the shading values across the triangle's surface\n",
    "                    color = ((material_constants[\"Kt\"] * texture_color) + (alpha * shade_vertex[0] + beta * shade_vertex[1] + gamma * shade_vertex[2])).astype(int)\n",
    "                    color = tuple(np.clip(color, 0, 255))\n",
    "                    # print(color)\n",
    "                    draw.point((x, y), color)\n",
    "                    z_buffer[y, x] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65dd4999-de91-4a97-b5ee-07fd86c963da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_vectors(vertex_vectors, alpha, beta, gamma, normalize_result=True):\n",
    "    v0, v1, v2 = vertex_vectors[0], vertex_vectors[1], vertex_vectors[2]\n",
    "    interpolated_vector = [alpha * v0[i] + beta * v1[i] + gamma * v2[i] for i in range(len(v0))]\n",
    "    if normalize_result:\n",
    "        return normalize(interpolated_vector)\n",
    "    else:\n",
    "        return interpolated_vector\n",
    "\n",
    "def rasterize_triangle_with_phong_shading(draw, z_buffer, camera_space_vertex, raster_vertex, normal_vertex, texture_vertex):\n",
    "    v0, v1, v2 = raster_vertex[0], raster_vertex[1], raster_vertex[2]\n",
    "    normal_v0, normal_v1, normal_v2 = normal_vertex[0], normal_vertex[1], normal_vertex[2]\n",
    "    t0, t1, t2 = texture_vertex[0], texture_vertex[1], texture_vertex[2]\n",
    "\n",
    "    canvas_width, canvas_height = draw.im.size\n",
    "\n",
    "    xmin, xmax, ymin, ymax = clip_and_clamp_coordinates(v0, v1, v2, canvas_width, canvas_height)\n",
    "\n",
    "    f12_v0 = line_eq(v1, v2, v0[0], v0[1])\n",
    "    f20_v1 = line_eq(v2, v0, v1[0], v1[1])\n",
    "    f01_v2 = line_eq(v0, v1, v2[0], v2[1])\n",
    "\n",
    "    for y in range(ymin, ymax + 1):\n",
    "        for x in range(xmin, xmax + 1):\n",
    "            alpha = line_eq(v1, v2, x, y) / f12_v0\n",
    "            beta = line_eq(v2, v0, x, y) / f20_v1\n",
    "            gamma = line_eq(v0, v1, x, y) / f01_v2\n",
    "\n",
    "            if 0 <= alpha <= 1 and 0 <= beta <= 1 and 0 <= gamma <= 1:\n",
    "                z = alpha * v0[2] + beta * v1[2] + gamma * v2[2]\n",
    "                if z < z_buffer[y, x]:\n",
    "                    # Interpolate the normal at the current pixel\n",
    "                    interpolated_normal = interpolate_vectors(normal_vertex, alpha, beta, gamma, normalize_result=True)\n",
    "                    interpolated_camera_space_vertices = interpolate_vectors(camera_space_vertex, alpha, beta, gamma, normalize_result=False)\n",
    "                    illumination = compute_illumination(interpolated_normal, interpolated_camera_space_vertices)\n",
    "                    # print(illumination)\n",
    "                    # Load texture\n",
    "                    interpolated_t_over_z = np.array(alpha * t0 / v0[2] + beta * t1 / v1[2] + gamma * t2 / v2[2])\n",
    "                    z_at_pixel = 1 / np.array(alpha * (1 / v0[2]) + beta * (1 / v1[2]) + gamma * (1 / v2[2]))\n",
    "                    interpolated_t_over_z *= z_at_pixel\n",
    "                    texture_color = compute_triangle_color(interpolated_t_over_z[0], interpolated_t_over_z[1])\n",
    "                    \n",
    "                    # Interpolate the shading values across the triangle's surface\n",
    "                    color = ((material_constants[\"Kt\"] * texture_color) + (alpha * illumination[0] + beta * illumination[1] + gamma * illumination[2])).astype(int)\n",
    "                    # print(color)\n",
    "                    color = tuple(np.clip(color, 0, 255))\n",
    "                    # print(color)\n",
    "                    \n",
    "                    draw.point((x, y), fill=color)\n",
    "                    z_buffer[y, x] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77e8541f-b433-4d19-a7c6-881f23ed69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each triangle in the teapot data and raster vertices together\n",
    "aa=-1\n",
    "frames =[]\n",
    "for camera_space_aa_vertices, normal_aa_vertices, raster_aa_vertices, texture_aa_vertices in zip(camera_space_vertices, normal_vertices, raster_vertices, texture_vertices):\n",
    "    image, z_buffer = initialize_image_and_z_buffer(canvas_size)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = draw.im.size\n",
    "    \n",
    "    aa+=1\n",
    "    for camera_space_vertex_list, normal_vertex_list, raster_vertex_list, texture_vertex_list in zip(camera_space_aa_vertices, normal_aa_vertices, raster_aa_vertices, texture_aa_vertices):\n",
    "        for camera_space_vertex, normal_vertex, raster_vertex, texture_vertex in zip(camera_space_vertex_list, normal_vertex_list, raster_vertex_list, texture_vertex_list):\n",
    "            rasterize_triangle_with_phong_shading(draw, z_buffer, camera_space_vertex, raster_vertex, normal_vertex, texture_vertex)\n",
    "    \n",
    "    image.save(f'teapot_filter_{aa}.png')\n",
    "    frames.append(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b783719-af5a-4ee2-b028-bff94b8ec5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, z_buffer = initialize_image_and_z_buffer(canvas_size)\n",
    "draw = ImageDraw.Draw(image)\n",
    "image_width, image_height = draw.im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e7d5b6d-0fc2-401f-b8be-70af1237f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(image_height):\n",
    "    for x in range(image_width):\n",
    "        \n",
    "        color = np.zeros(3)\n",
    "\n",
    "        for frame_index, frame in enumerate(frames):\n",
    "            anti_aliasing_weight = anti_aliasing_table[frame_index][2]\n",
    "            color += anti_aliasing_weight * frame[y][x]\n",
    "\n",
    "        draw.point((x, y), tuple(color.astype(int)))\n",
    "\n",
    "image.save(f\"teapot_filter_final.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e6b0c-127f-4007-9530-f8ebf42517c6",
   "metadata": {},
   "source": [
    "# Printing raster vertices to show the changes through dx and dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "469ec4b9-676d-4a29-8e47-e2a55dbb6ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(335.8320017100742, 138.2536164191956, 1.0197478488416427),\n",
       " (322.570801925011, 144.86815334026312, 0.9883517232443818),\n",
       " (321.71411058628604, 140.16713617241447, 0.987313344371785)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_vertices[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc7b6089-5849-4a14-90c6-5b3b497c96cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(335.83382167093527, 138.25396866968484, 1.0197478488416427),\n",
       " (322.572621885872, 144.86850559075236, 0.9883517232443818),\n",
       " (321.7159305471471, 140.16748842290372, 0.987313344371785)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_vertices[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dee421f-269e-463e-9380-b56105cc6570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(335.8335476983325, 138.25302933504688, 1.0197478488416427),\n",
       " (322.57234791326925, 144.8675662561144, 0.9883517232443818),\n",
       " (321.7156565745443, 140.16654908826575, 0.987313344371785)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_vertices[2][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa2e43ac-1d95-4e54-b1b7-aa2a1ffd97f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(335.83268664158106, 138.25230526459677, 1.0197478488416427),\n",
       " (322.5714868565178, 144.8668421856643, 0.9883517232443818),\n",
       " (321.7147955177929, 140.16582501781565, 0.987313344371785)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_vertices[3][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cadd679-0676-4a14-8357-d99929b2aea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(335.83415435195286, 138.25179645833452, 1.0197478488416427),\n",
       " (322.5729545668896, 144.86633337940205, 0.9883517232443818),\n",
       " (321.7162632281647, 140.1653162115534, 0.987313344371785)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_vertices[4][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44349cc0-6239-4755-bb99-930e25bfaa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(335.8324126689783, 138.25148334678855, 1.0197478488416427),\n",
       " (322.57121288391505, 144.86602026785607, 0.9883517232443818),\n",
       " (321.7145215451901, 140.16500310000743, 0.987313344371785)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_vertices[5][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
