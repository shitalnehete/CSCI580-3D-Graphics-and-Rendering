{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d10eb53-438f-4543-9d5a-5160e70c3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6327ca25-fcbd-4fa6-a90e-ff4ee21a7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "teapot1 teapot [1, 0, 0] 0.5 0.75 0.9 2.0\n",
      "Ry 0\n",
      "S [1, 0.5, 1]\n",
      "T [3, 0, 0]\n",
      "\n",
      "teapot2 teapot [0, 1, 0] 0.35 0.5 0.9 5.0\n",
      "Ry 90\n",
      "S [1, 1, 1]\n",
      "T [0, 0, -3]\n",
      "no scaling\n",
      "teapot3 teapot [0, 0, 1] 0.15 0.35 0.9 10.0\n",
      "Ry 180\n",
      "S [1, 1.5, 1]\n",
      "T [-3, 0, 0]\n",
      "\n",
      "teapot4 teapot [1, 1, 0] 0.05 0.15 0.9 20.0\n",
      "Ry 270\n",
      "S [1, 2, 1]\n",
      "T [0, 0, 3]\n",
      "\n",
      "\n",
      "Lights:\n",
      "L1 ambient [1, 1, 1] 0.2 None None\n",
      "L2 directional [1, 0.5, 1] 0.6 [10, 5, 0] [0, 0, 0]\n",
      "\n",
      "Camera:\n",
      "[3, 4, 10] [0, 0, 0] [3, 10, 1, -1, 1, -1] [512, 512]\n"
     ]
    }
   ],
   "source": [
    "# Define classes for different scene elements\n",
    "class Material:\n",
    "    def __init__(self, Cs, Ka, Kd, Ks, n):\n",
    "        self.Cs = Cs\n",
    "        self.Ka = Ka\n",
    "        self.Kd = Kd\n",
    "        self.Ks = Ks\n",
    "        self.n = n\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self, transform_type, value):\n",
    "        self.transform_type = transform_type\n",
    "        self.value = value\n",
    "\n",
    "class Shape:\n",
    "    def __init__(self, id, geometry, material, transforms, notes=\"\"):\n",
    "        self.id = id\n",
    "        self.geometry = geometry\n",
    "        self.material = material\n",
    "        self.transforms = transforms\n",
    "        self.notes = notes\n",
    "\n",
    "class Light:\n",
    "    def __init__(self, id, type, color, intensity, from_pos=None, to_pos=None):\n",
    "        self.id = id\n",
    "        self.type = type\n",
    "        self.color = color\n",
    "        self.intensity = intensity\n",
    "        self.from_pos = from_pos\n",
    "        self.to_pos = to_pos\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, from_pos, to_pos, bounds, resolution):\n",
    "        self.from_pos = from_pos\n",
    "        self.to_pos = to_pos\n",
    "        self.bounds = bounds\n",
    "        self.resolution = resolution\n",
    "\n",
    "# Parse the scene JSON file\n",
    "def parse_scene(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        scene_data = json.load(file)\n",
    "\n",
    "    shapes = []\n",
    "    lights = []\n",
    "    camera = None\n",
    "\n",
    "    # Parse shapes\n",
    "    for shape_data in scene_data['scene']['shapes']:\n",
    "        transforms = []\n",
    "        for transform_data in shape_data['transforms']:\n",
    "            transform_type, value = next(iter(transform_data.items()))\n",
    "            transforms.append(Transform(transform_type, value))\n",
    "        shapes.append(Shape(shape_data.get('id'), shape_data['geometry'], \n",
    "                            Material(shape_data['material']['Cs'], shape_data['material']['Ka'],\n",
    "                                     shape_data['material']['Kd'], shape_data['material']['Ks'],\n",
    "                                     shape_data['material']['n']), transforms, shape_data.get('notes')))\n",
    "\n",
    "    # Parse lights\n",
    "    for light_data in scene_data['scene']['lights']:\n",
    "        if light_data['type'] == 'ambient':\n",
    "            lights.append(Light(light_data['id'], 'ambient', light_data['color'], light_data['intensity']))\n",
    "        elif light_data['type'] == 'directional':\n",
    "            lights.append(Light(light_data['id'], 'directional', light_data['color'], light_data['intensity'],\n",
    "                                 light_data['from'], light_data['to']))\n",
    "\n",
    "    # Parse camera\n",
    "    camera_data = scene_data['scene']['camera']\n",
    "    camera = Camera(camera_data['from'], camera_data['to'], camera_data['bounds'], camera_data['resolution'])\n",
    "\n",
    "    return shapes, lights, camera\n",
    "\n",
    "# Test the parser\n",
    "shapes, lights, camera = parse_scene('scene.json')\n",
    "print(\"Shapes:\")\n",
    "for shape in shapes:\n",
    "    print(shape.id, shape.geometry, shape.material.Cs, shape.material.Ka, shape.material.Kd, shape.material.Ks, shape.material.n)\n",
    "    for transform in shape.transforms:\n",
    "        print(transform.transform_type, transform.value)\n",
    "    print(shape.notes)\n",
    "print(\"\\nLights:\")\n",
    "for light in lights:\n",
    "    print(light.id, light.type, light.color, light.intensity, light.from_pos, light.to_pos)\n",
    "print(\"\\nCamera:\")\n",
    "print(camera.from_pos, camera.to_pos, camera.bounds, camera.resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0627481-556c-4411-a41c-f98b4eee68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_matrix(scale_factors):\n",
    "    if len(scale_factors) != 3:\n",
    "        raise ValueError(\"Scale factors must be provided for x, y, and z axes.\")\n",
    "    scale_matrix = np.diag(scale_factors + [1])  # Add 1 for the homogeneous coordinate\n",
    "    return scale_matrix\n",
    "\n",
    "def rotation_matrix_y(angle_deg):\n",
    "    angle_rad = np.radians(angle_deg)\n",
    "    cos_theta = np.cos(angle_rad)\n",
    "    sin_theta = np.sin(angle_rad)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_theta, 0, sin_theta, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [-sin_theta, 0, cos_theta, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    return rotation_matrix\n",
    "\n",
    "def translation_matrix(translation):\n",
    "    if len(translation) != 3:\n",
    "        raise ValueError(\"Translation must be provided for x, y, and z axes.\")\n",
    "    tx, ty, tz = translation\n",
    "    translation_matrix = np.array([\n",
    "        [1, 0, 0, tx],\n",
    "        [0, 1, 0, ty],\n",
    "        [0, 0, 1, tz],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    return translation_matrix\n",
    "\n",
    "def combine_transformations(scale_factors, angle_deg, translation):\n",
    "    scale_mat = scale_matrix(scale_factors)\n",
    "    rotation_mat_y = rotation_matrix_y(angle_deg)\n",
    "    translation_mat = translation_matrix(translation)\n",
    "    combined_mat = translation_mat @ rotation_mat_y @ scale_mat  # Order of application: scale, rotate, translate\n",
    "    return combined_mat\n",
    "\n",
    "def normal_combine_transformations(scale_factors, angle_deg):\n",
    "    scale_mat = scale_matrix(scale_factors)\n",
    "    rotation_mat_y = rotation_matrix_y(angle_deg)\n",
    "    # translation_mat = translation_matrix(translation)\n",
    "    combined_mat = rotation_mat_y @ scale_mat  # Order of application: scale, rotate, translate\n",
    "    return combined_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df567344-437e-43ee-93e2-5479f96b2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_camera_axes(cam_from, cam_to):\n",
    "    cam_up = [0, 1, 0]\n",
    "    n = np.array(cam_from, dtype=np.float64) - np.array(cam_to, dtype=np.float64)\n",
    "    n /= np.linalg.norm(n)\n",
    "    u = np.cross(np.array(cam_up, dtype=np.float64), n)\n",
    "    u /= np.linalg.norm(u)\n",
    "    v = np.cross(n, u)\n",
    "    r = cam_from\n",
    "    return u, v, n, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127de0ff-83e5-4a2d-8595-3bcce79f402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    return vector / np.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ebbdd2-d8fe-4725-b3b4-e64933b02582",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_aliasing_table = np.array(\n",
    "        [\n",
    "            [-0.52, 0.38, 0.128],\n",
    "            [0.41, 0.56, 0.119],\n",
    "            [0.27, 0.08, 0.294],\n",
    "            [-0.17, -0.29, 0.249],\n",
    "            [0.58, -0.55, 0.104],\n",
    "            [-0.31, -0.71, 0.106],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3350f75-e3b3-4045-9c68-97abffe863ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_image_and_z_buffer(canvas_size):\n",
    "    image = Image.new('RGB', (canvas_size, canvas_size), (0, 0, 0))\n",
    "    z_buffer = np.full((canvas_size, canvas_size), np.inf, dtype=float)\n",
    "    return image, z_buffer\n",
    "\n",
    "def perspective_projection_matrix(near, far, left, right, top, bottom):\n",
    "    matrix = np.zeros((4, 4))\n",
    "    matrix[0, 0] = 2 * near / (right - left)\n",
    "    matrix[1, 1] = 2 * near / (top - bottom)\n",
    "    matrix[0, 2] = (right + left) / (right - left)\n",
    "    matrix[1, 2] = (top + bottom) / (top - bottom)\n",
    "    matrix[2, 2] = -(far + near) / (far - near)\n",
    "    matrix[2, 3] = -2 * far * near / (far - near)\n",
    "    matrix[3, 2] = -1\n",
    "    return matrix\n",
    "\n",
    "def camera_matrix(u, v, n, r):\n",
    "    matrix = np.eye(4)\n",
    "    matrix[0, :3] = u\n",
    "    matrix[1, :3] = v\n",
    "    matrix[2, :3] = n\n",
    "    matrix[3, :3] = 0, 0, 0\n",
    "    matrix[0, 3] = -np.dot(r, u)\n",
    "    matrix[1, 3] = -np.dot(r, v)\n",
    "    matrix[2, 3] = -np.dot(r, n)\n",
    "    matrix[3, 3] = 1\n",
    "    return matrix\n",
    "\n",
    "# Constants\n",
    "canvas_size = 512\n",
    "\n",
    "# Load teapot data from JSON\n",
    "with open('teapot.json', 'r') as f:\n",
    "    teapot_data = json.load(f)\n",
    "\n",
    "# Initialize image and z-buffer\n",
    "image, z_buffer = initialize_image_and_z_buffer(canvas_size)\n",
    "\n",
    "draw = ImageDraw.Draw(image)\n",
    "image_width, image_height = draw.im.size\n",
    "\n",
    "# Define the camera space axes\n",
    "u, v, n, r = calculate_camera_axes(camera.from_pos, camera.to_pos)\n",
    "near, far, right, left, top, bottom = camera.bounds\n",
    "\n",
    "# Create the camera matrix\n",
    "camera_mat = camera_matrix(u, v, n, r)\n",
    "# print(camera_mat)\n",
    "\n",
    "# Create perspective projection matrix\n",
    "perspective_mat = perspective_projection_matrix(near, far, left, right, top, bottom)\n",
    "# print(perspective_mat)\n",
    "\n",
    "camera_space_vertices = []\n",
    "normal_vertices = []\n",
    "raster_vertices = []\n",
    "\n",
    "for anti_aliasing_values in anti_aliasing_table:\n",
    "\n",
    "    anti_aliasing_dx = anti_aliasing_values[0] / (image_width - 1)\n",
    "    anti_aliasing_dy = anti_aliasing_values[1] / (image_height - 1)\n",
    "\n",
    "    camera_space_vertices_antialiasing_temp = []\n",
    "    raster_vertices_antialiasing_temp = []\n",
    "    normal_vertices_antialiasing_temp = []\n",
    "\n",
    "    for shape in shapes:\n",
    "        camera_space_vertices_temp = []\n",
    "        raster_vertices_temp = []\n",
    "        normal_vertices_temp = []\n",
    "        \n",
    "        combine_transformations_matrix = combine_transformations(shape.transforms[1].value, shape.transforms[0].value, shape.transforms[2].value)\n",
    "        inverse_transpose_matrix = np.linalg.inv(normal_combine_transformations(shape.transforms[1].value, shape.transforms[0].value)).T\n",
    "        \n",
    "        # print(combine_transformations_matrix)\n",
    "        # print(inverse_transpose_matrix)\n",
    "        \n",
    "        for triangle in teapot_data['data']:\n",
    "            camera_space_vertex = []\n",
    "            raster_vertex = []\n",
    "            normal_vertex = []\n",
    "            for vertex in [triangle['v0'], triangle['v1'], triangle['v2']]:\n",
    "                v = np.array(vertex['v'][:3] + [1.0])  # Add 1.0 for 4D\n",
    "                v = combine_transformations_matrix @ v\n",
    "                \n",
    "                v_camera = camera_mat @ v\n",
    "                v_camera = v_camera[:3] / v_camera[3]\n",
    "                \n",
    "                camera_space_vertex.append([v_camera[0], v_camera[1], v_camera[2]])\n",
    "                \n",
    "                v_camera = np.append(v_camera, 1)\n",
    "                v_ndc = perspective_mat @ v_camera\n",
    "                v_ndc = v_ndc[:3] / v_ndc[3]\n",
    "                v_ndc = np.append(v_ndc, 1)\n",
    "                \n",
    "                x = (v_ndc[0] + 1) * ((image_width-1) / 2)\n",
    "                y = (1 - v_ndc[1]) * ((image_height-1) / 2)\n",
    "                z = v_ndc[2]\n",
    "\n",
    "                # Apply anti-aliasing\n",
    "                x += anti_aliasing_dx\n",
    "                y += anti_aliasing_dy\n",
    "                \n",
    "                raster_vertex.append((x, y, z))\n",
    "               \n",
    "                n = np.array(vertex['n'][:3] + [1.0])  # Add 1.0 for 4D\n",
    "                n = inverse_transpose_matrix @ n\n",
    "                n = n[:3] #/ n[3]\n",
    "                \n",
    "                normal_vertex.append(normalize(n))\n",
    "                # break\n",
    "                \n",
    "            raster_vertices_temp.append(raster_vertex)\n",
    "            # print(raster_vertices_temp)\n",
    "            camera_space_vertices_temp.append(camera_space_vertex)\n",
    "            normal_vertices_temp.append(normal_vertex)\n",
    "            # break\n",
    " \n",
    "        raster_vertices_antialiasing_temp.append(raster_vertices_temp)\n",
    "        camera_space_vertices_antialiasing_temp.append(camera_space_vertices_temp)\n",
    "        normal_vertices_antialiasing_temp.append(normal_vertices_temp)\n",
    "\n",
    "    raster_vertices.append(raster_vertices_antialiasing_temp)\n",
    "    camera_space_vertices.append(camera_space_vertices_antialiasing_temp)\n",
    "    normal_vertices.append(normal_vertices_antialiasing_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6013597-0f6e-4cfd-a91c-1417dd92c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambient_intensity = lights[0].intensity\n",
    "light_intensity = lights[1].intensity\n",
    "light_direction = normalize([lights[1].from_pos[0] - lights[1].to_pos[0], lights[1].from_pos[1] - lights[1].to_pos[1], lights[1].from_pos[2] - lights[1].to_pos[2]])\n",
    "viewer_position = np.array(camera.from_pos)\n",
    "material_constants = {\n",
    "    \"0\": {\"Cs\": np.array(shapes[0].material.Cs), \"Ka\": shapes[0].material.Ka, \"Kd\": shapes[0].material.Kd, \"Ks\": shapes[0].material.Ks, \"n\": shapes[0].material.n},\n",
    "    \"1\": {\"Cs\": np.array(shapes[1].material.Cs), \"Ka\": shapes[1].material.Ka, \"Kd\": shapes[1].material.Kd, \"Ks\": shapes[1].material.Ks, \"n\": shapes[1].material.n},\n",
    "    \"2\": {\"Cs\": np.array(shapes[2].material.Cs), \"Ka\": shapes[2].material.Ka, \"Kd\": shapes[2].material.Kd, \"Ks\": shapes[2].material.Ks, \"n\": shapes[2].material.n},\n",
    "    \"3\": {\"Cs\": np.array(shapes[3].material.Cs), \"Ka\": shapes[3].material.Ka, \"Kd\": shapes[3].material.Kd, \"Ks\": shapes[3].material.Ks, \"n\": shapes[3].material.n}\n",
    "}\n",
    "ambient_color = np.array(lights[0].color)\n",
    "light_color = np.array(lights[1].color)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a620b2-7895-4750-9525-a898c582954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(a, b):\n",
    "    return np.dot(a, b)\n",
    "\n",
    "def compute_diffuse(normal, light_direction, kd):\n",
    "    return max(0, dot_product(normal, light_direction)) * light_color * light_intensity * kd\n",
    "\n",
    "def compute_specular(normal, light_direction, vertex_position, ks, n):\n",
    "    view_direction = normalize(viewer_position - vertex_position)\n",
    "    H = normalize (light_direction + view_direction)\n",
    "    specular_term = max(0, dot_product(H, normal)) ** n\n",
    "    return specular_term * light_color * light_intensity * ks\n",
    "\n",
    "def compute_ambient(ka):\n",
    "    return ambient_intensity * ka * ambient_color\n",
    "\n",
    "def compute_illumination(normal, vertex_position, teapot_id):\n",
    "    Cs = material_constants[teapot_id][\"Cs\"]\n",
    "    Ka = material_constants[teapot_id][\"Ka\"]\n",
    "    Kd = material_constants[teapot_id][\"Kd\"]\n",
    "    Ks = material_constants[teapot_id][\"Ks\"]\n",
    "    n = material_constants[teapot_id][\"n\"]\n",
    "    ambient = compute_ambient(Ka)\n",
    "    diffuse = compute_diffuse(normal, light_direction, Kd)\n",
    "    specular = compute_specular(normal, light_direction, vertex_position, Ks, n)\n",
    "    return (Cs * (ambient + diffuse) + specular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a48405-78aa-4f0e-a44d-9916e7307a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=-1\n",
    "# all_teapot_shades = []\n",
    "# for camera_space_vertex_list, normal_vertex_list in zip(camera_space_vertices, normal_vertices):\n",
    "#     i+=1\n",
    "#     teapot_shade = []\n",
    "#     for camera_space_triangle_vertices, normal_triangle_vertices in zip(camera_space_vertex_list, normal_vertex_list):\n",
    "#         triangle_shade = []\n",
    "#         for camera_space_vertex, normal_vertex in zip(camera_space_triangle_vertices, normal_triangle_vertices):\n",
    "#             normal_vertex = np.array(normal_vertex)\n",
    "#             camera_space_vertex = np.array(camera_space_vertex)\n",
    "#             triangle_shade.append(compute_illumination(normal_vertex, camera_space_vertex, str(i)))\n",
    "#         # print(triangle_shade)\n",
    "#         teapot_shade.append(triangle_shade)\n",
    "#         # print(teapot_shade)\n",
    "#     all_teapot_shades.append(teapot_shade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4b1aca9-dc59-4e05-820e-d9d132582b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_triangle_color(shade_values):\n",
    "    return tuple(int(value * 255.0) for value in shade_values)\n",
    "\n",
    "def line_eq(p1, p2, x, y):\n",
    "    return (p1[1] - p2[1]) * x + (p2[0] - p1[0]) * y + p1[0] * p2[1] - p2[0] * p1[1]\n",
    "\n",
    "def clip_and_clamp_coordinates(v0, v1, v2, canvas_width, canvas_height):\n",
    "    xmin, xmax = max(np.floor(min(v0[0], v1[0], v2[0])), 0), min(np.ceil(max(v0[0], v1[0], v2[0])), canvas_width - 1)\n",
    "    ymin, ymax = max(np.floor(min(v0[1], v1[1], v2[1])), 0), min(np.ceil(max(v0[1], v1[1], v2[1])), canvas_height - 1)\n",
    "    return int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "\n",
    "def rasterize_triangle(draw, z_buffer, raster_vertex, shade_vertex):\n",
    "    v0, v1, v2 = raster_vertex[0], raster_vertex[1], raster_vertex[2]\n",
    "\n",
    "    canvas_width, canvas_height = draw.im.size\n",
    "\n",
    "    # Clip and clamp the triangle's bounding box coordinates\n",
    "    xmin, xmax, ymin, ymax = clip_and_clamp_coordinates(v0, v1, v2, canvas_width, canvas_height)\n",
    "\n",
    "    f12_v0 = line_eq(v1, v2, v0[0], v0[1])\n",
    "    f20_v1 = line_eq(v2, v0, v1[0], v1[1])\n",
    "    f01_v2 = line_eq(v0, v1, v2[0], v2[1])\n",
    "\n",
    "    for y in range(ymin, ymax):\n",
    "        for x in range(xmin, xmax):\n",
    "            alpha = line_eq(v1, v2, x, y) / f12_v0\n",
    "            beta = line_eq(v2, v0, x, y) / f20_v1\n",
    "            gamma = line_eq(v0, v1, x, y) / f01_v2\n",
    "\n",
    "            if 0 <= alpha <= 1 and 0 <= beta <= 1 and 0 <= gamma <= 1:\n",
    "                z = alpha * v0[2] + beta * v1[2] + gamma * v2[2]\n",
    "                # print(z_buffer[y, x])\n",
    "                if z < z_buffer[y, x]:\n",
    "                    # Interpolate the shading values across the triangle's surface\n",
    "                    shade_value = alpha * shade_vertex[0] + beta * shade_vertex[1] + gamma * shade_vertex[2]\n",
    "                    # print(shade_value)\n",
    "                    color = compute_triangle_color(shade_value)\n",
    "                    draw.point((x, y), color)\n",
    "                    z_buffer[y, x] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc9e98f9-5dcb-45cf-98ec-b7639bb44b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over each triangle in the teapot data and raster vertices together\n",
    "# for shade_vertex_list, raster_vertex_list in zip(all_teapot_shades, raster_vertices):\n",
    "#     for shade_vertex, raster_vertex in zip(shade_vertex_list, raster_vertex_list):\n",
    "#         rasterize_triangle(draw, z_buffer, raster_vertex, shade_vertex)\n",
    "\n",
    "# # Save the rendered image\n",
    "# image.save('teapot_gouraud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65dd4999-de91-4a97-b5ee-07fd86c963da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_vectors(vertex_vectors, alpha, beta, gamma, normalize_result=True):\n",
    "    v0, v1, v2 = vertex_vectors[0], vertex_vectors[1], vertex_vectors[2]\n",
    "    interpolated_vector = [alpha * v0[i] + beta * v1[i] + gamma * v2[i] for i in range(len(v0))]\n",
    "    if normalize_result:\n",
    "        return normalize(interpolated_vector)\n",
    "    else:\n",
    "        return interpolated_vector\n",
    "\n",
    "def rasterize_triangle_with_phong_shading(draw, z_buffer, camera_space_vertex, raster_vertex, normal_vertex, teapot_id):\n",
    "    v0, v1, v2 = raster_vertex[0], raster_vertex[1], raster_vertex[2]\n",
    "    normal_v0, normal_v1, normal_v2 = normal_vertex[0], normal_vertex[1], normal_vertex[2]\n",
    "\n",
    "    canvas_width, canvas_height = draw.im.size\n",
    "\n",
    "    xmin, xmax, ymin, ymax = clip_and_clamp_coordinates(v0, v1, v2, canvas_width, canvas_height)\n",
    "\n",
    "    f12_v0 = line_eq(v1, v2, v0[0], v0[1])\n",
    "    f20_v1 = line_eq(v2, v0, v1[0], v1[1])\n",
    "    f01_v2 = line_eq(v0, v1, v2[0], v2[1])\n",
    "\n",
    "    for y in range(ymin, ymax + 1):\n",
    "        for x in range(xmin, xmax + 1):\n",
    "            alpha = line_eq(v1, v2, x, y) / f12_v0\n",
    "            beta = line_eq(v2, v0, x, y) / f20_v1\n",
    "            gamma = line_eq(v0, v1, x, y) / f01_v2\n",
    "\n",
    "            if 0 <= alpha <= 1 and 0 <= beta <= 1 and 0 <= gamma <= 1:\n",
    "                z = alpha * v0[2] + beta * v1[2] + gamma * v2[2]\n",
    "                if z < z_buffer[y, x]:\n",
    "                    # Interpolate the normal at the current pixel\n",
    "                    interpolated_normal = interpolate_vectors(normal_vertex, alpha, beta, gamma, normalize_result=True)\n",
    "                    interpolated_camera_space_vertices = interpolate_vectors(camera_space_vertex, alpha, beta, gamma, normalize_result=False)\n",
    "                    illumination = compute_illumination(interpolated_normal, interpolated_camera_space_vertices, teapot_id)\n",
    "                    draw.point((x, y), fill=compute_triangle_color(illumination))\n",
    "                    z_buffer[y, x] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77e8541f-b433-4d19-a7c6-881f23ed69ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/wrg2p2fn14ndzvwb71w_ffyr0000gn/T/ipykernel_3356/1877593876.py:23: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  alpha = line_eq(v1, v2, x, y) / f12_v0\n",
      "/var/folders/hx/wrg2p2fn14ndzvwb71w_ffyr0000gn/T/ipykernel_3356/1877593876.py:24: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  beta = line_eq(v2, v0, x, y) / f20_v1\n",
      "/var/folders/hx/wrg2p2fn14ndzvwb71w_ffyr0000gn/T/ipykernel_3356/1877593876.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  gamma = line_eq(v0, v1, x, y) / f01_v2\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each triangle in the teapot data and raster vertices together\n",
    "aa=-1\n",
    "frames =[]\n",
    "for camera_space_aa_vertices, normal_aa_vertices, raster_aa_vertices in zip(camera_space_vertices, normal_vertices, raster_vertices):\n",
    "    \n",
    "    image, z_buffer = initialize_image_and_z_buffer(canvas_size)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = draw.im.size\n",
    "    \n",
    "    aa+=1\n",
    "    i=-1\n",
    "    for camera_space_vertex_list, normal_vertex_list, raster_vertex_list in zip(camera_space_aa_vertices, normal_aa_vertices, raster_aa_vertices):\n",
    "        i+=1\n",
    "        for camera_space_vertex, normal_vertex, raster_vertex in zip(camera_space_vertex_list, normal_vertex_list, raster_vertex_list):\n",
    "            rasterize_triangle_with_phong_shading(draw, z_buffer, camera_space_vertex, raster_vertex, normal_vertex, str(i))\n",
    "    \n",
    "    image.save(f'teapot_filter_{aa}.png')\n",
    "    frames.append(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "621aadcc-ffc6-4f15-8a4b-897cb47bfaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, z_buffer = initialize_image_and_z_buffer(canvas_size)\n",
    "draw = ImageDraw.Draw(image)\n",
    "image_width, image_height = draw.im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b783719-af5a-4ee2-b028-bff94b8ec5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(image_height):\n",
    "    for x in range(image_width):\n",
    "        \n",
    "        color = np.zeros(3)\n",
    "\n",
    "        for frame_index, frame in enumerate(frames):\n",
    "            anti_aliasing_weight = anti_aliasing_table[frame_index][2]\n",
    "            color += anti_aliasing_weight * frame[y][x]\n",
    "\n",
    "        draw.point((x, y), tuple(color.astype(int)))\n",
    "\n",
    "image.save(f\"teapot_filter_final.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fe915-7a7a-4376-861b-7b1861e72aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
